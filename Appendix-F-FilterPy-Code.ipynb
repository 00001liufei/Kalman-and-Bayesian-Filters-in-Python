{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](http://nbviewer.ipython.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FilterPy Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convienence I have loaded several of FilterPy's core algorithms into this appendix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/rlabbe/filterpy/master/filterpy/kalman/kalman_filter.py\n",
    "\n",
    "\"\"\"Copyright 2015 Roger R Labbe Jr.\n",
    "\n",
    "FilterPy library.\n",
    "http://github.com/rlabbe/filterpy\n",
    "\n",
    "Documentation at:\n",
    "https://filterpy.readthedocs.org\n",
    "\n",
    "Supporting book at:\n",
    "https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python\n",
    "\n",
    "This is licensed under an MIT license. See the readme.MD file\n",
    "for more information.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "from filterpy.common import setter, setter_1d, setter_scalar, dot3\n",
    "import numpy as np\n",
    "from numpy import dot, zeros, eye, isscalar\n",
    "import scipy.linalg as linalg\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "class KalmanFilter(object):\n",
    "    \"\"\" Implements a Kalman filter. You are responsible for setting the\n",
    "    various state variables to reasonable values; the defaults  will\n",
    "    not give you a functional filter.\n",
    "\n",
    "    You will have to set the following attributes after constructing this\n",
    "    object for the filter to perform properly. Please note that there are\n",
    "    various checks in place to ensure that you have made everything the\n",
    "    'correct' size. However, it is possible to provide incorrectly sized\n",
    "    arrays such that the linear algebra can not perform an operation.\n",
    "    It can also fail silently - you can end up with matrices of a size that\n",
    "    allows the linear algebra to work, but are the wrong shape for the problem\n",
    "    you are trying to solve.\n",
    "\n",
    "    **Attributes**\n",
    "\n",
    "    x : numpy.array(dim_x, 1)\n",
    "        state estimate vector\n",
    "\n",
    "    P : numpy.array(dim_x, dim_x)\n",
    "        covariance estimate matrix\n",
    "\n",
    "    R : numpy.array(dim_z, dim_z)\n",
    "        measurement noise matrix\n",
    "\n",
    "    Q : numpy.array(dim_x, dim_x)\n",
    "        process noise matrix\n",
    "\n",
    "    F : numpy.array()\n",
    "        State Transition matrix\n",
    "\n",
    "    H : numpy.array(dim_x, dim_x)\n",
    "\n",
    "\n",
    "    You may read the following attributes.\n",
    "\n",
    "    **Readable Attributes**\n",
    "\n",
    "    y : numpy.array\n",
    "        Residual of the update step.\n",
    "\n",
    "    K : numpy.array(dim_x, dim_z)\n",
    "        Kalman gain of the update step\n",
    "\n",
    "    S :  numpy.array\n",
    "        Systen uncertaintly projected to measurement space\n",
    "\n",
    "    likelihood : scalar\n",
    "        Likelihood of last measurment update.\n",
    "\n",
    "    log_likelihood : scalar\n",
    "        Log likelihood of last measurment update.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, dim_x, dim_z, dim_u=0):\n",
    "        \"\"\" Create a Kalman filter. You are responsible for setting the\n",
    "        various state variables to reasonable values; the defaults below will\n",
    "        not give you a functional filter.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        dim_x : int\n",
    "            Number of state variables for the Kalman filter. For example, if\n",
    "            you are tracking the position and velocity of an object in two\n",
    "            dimensions, dim_x would be 4.\n",
    "\n",
    "            This is used to set the default size of P, Q, and u\n",
    "\n",
    "        dim_z : int\n",
    "            Number of of measurement inputs. For example, if the sensor\n",
    "            provides you with position in (x,y), dim_z would be 2.\n",
    "\n",
    "        dim_u : int (optional)\n",
    "            size of the control input, if it is being used.\n",
    "            Default value of 0 indicates it is not used.\n",
    "        \"\"\"\n",
    "\n",
    "        assert dim_x > 0\n",
    "        assert dim_z > 0\n",
    "        assert dim_u >= 0\n",
    "\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_z = dim_z\n",
    "        self.dim_u = dim_u\n",
    "\n",
    "        self._x = zeros((dim_x,1)) # state\n",
    "        self._P = eye(dim_x)       # uncertainty covariance\n",
    "        self._Q = eye(dim_x)       # process uncertainty\n",
    "        self._B = 0                # control transition matrix\n",
    "        self._F = 0                # state transition matrix\n",
    "        self.H = 0                 # Measurement function\n",
    "        self.R = eye(dim_z)        # state uncertainty\n",
    "        self._alpha_sq = 1.        # fading memory control\n",
    "        self.M = 0                 # process-measurement cross correlation\n",
    "\n",
    "        # gain and residual are computed during the innovation step. We\n",
    "        # save them so that in case you want to inspect them for various\n",
    "        # purposes\n",
    "        self._K = 0 # kalman gain\n",
    "        self._y = zeros((dim_z, 1))\n",
    "        self._S = np.zeros((dim_z, dim_z)) # system uncertainty\n",
    "\n",
    "        # identity matrix. Do not alter this.\n",
    "        self._I = np.eye(dim_x)\n",
    "\n",
    "\n",
    "    def update(self, z, R=None, H=None):\n",
    "        \"\"\"\n",
    "        Add a new measurement (z) to the Kalman filter. If z is None, nothing\n",
    "        is changed.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        z : np.array\n",
    "            measurement for this update.\n",
    "\n",
    "        R : np.array, scalar, or None\n",
    "            Optionally provide R to override the measurement noise for this\n",
    "            one call, otherwise  self.R will be used.\n",
    "\n",
    "        H : np.array, or None\n",
    "            Optionally provide H to override the measurement function for this\n",
    "            one call, otherwise self.H will be used.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if z is None:\n",
    "            return\n",
    "\n",
    "        if R is None:\n",
    "            R = self.R\n",
    "        elif isscalar(R):\n",
    "            R = eye(self.dim_z) * R\n",
    "\n",
    "        # rename for readability and a tiny extra bit of speed\n",
    "        if H is None:\n",
    "            H = self.H\n",
    "        P = self._P\n",
    "        x = self._x\n",
    "\n",
    "        # y = z - Hx\n",
    "        # error (residual) between measurement and prediction\n",
    "        self._y = z - dot(H, x)\n",
    "\n",
    "        # S = HPH' + R\n",
    "        # project system uncertainty into measurement space\n",
    "        S = dot3(H, P, H.T) + R\n",
    "\n",
    "        mean = np.array(dot(H, x)).flatten()\n",
    "        flatz = np.array(z).flatten()\n",
    "\n",
    "        self.likelihood = multivariate_normal.pdf(flatz, mean, cov=S, allow_singular=True)\n",
    "        self.log_likelihood = multivariate_normal.logpdf(flatz, mean, cov=S, allow_singular=True)\n",
    "\n",
    "        # K = PH'inv(S)\n",
    "        # map system uncertainty into kalman gain\n",
    "        K = dot3(P, H.T, linalg.inv(S))\n",
    "\n",
    "        # x = x + Ky\n",
    "        # predict new x with residual scaled by the kalman gain\n",
    "        self._x = x + dot(K, self._y)\n",
    "\n",
    "        # P = (I-KH)P(I-KH)' + KRK'\n",
    "        I_KH = self._I - dot(K, H)\n",
    "        self._P = dot3(I_KH, P, I_KH.T) + dot3(K, R, K.T)\n",
    "\n",
    "        self._S = S\n",
    "        self._K = K\n",
    "\n",
    "\n",
    "\n",
    "    def update_correlated(self, z, R=None, H=None):\n",
    "        \"\"\" Add a new measurement (z) to the Kalman filter assuming that\n",
    "        process noise and measurement noise are correlated as defined in\n",
    "        the `self.M` matrix.\n",
    "\n",
    "        If z is None, nothing is changed.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        z : np.array\n",
    "            measurement for this update.\n",
    "\n",
    "        R : np.array, scalar, or None\n",
    "            Optionally provide R to override the measurement noise for this\n",
    "            one call, otherwise  self.R will be used.\n",
    "\n",
    "        H : np.array,  or None\n",
    "            Optionally provide H to override the measurement function for this\n",
    "            one call, otherwise  self.H will be used.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if z is None:\n",
    "            return\n",
    "\n",
    "        if R is None:\n",
    "            R = self.R\n",
    "        elif isscalar(R):\n",
    "            R = eye(self.dim_z) * R\n",
    "\n",
    "        # rename for readability and a tiny extra bit of speed\n",
    "        if H is None:\n",
    "            H = self.H\n",
    "        x = self._x\n",
    "        P = self._P\n",
    "        M = self.M\n",
    "\n",
    "        # y = z - Hx\n",
    "        # error (residual) between measurement and prediction\n",
    "        self._y = z - dot(H, x)\n",
    "\n",
    "        # project system uncertainty into measurement space\n",
    "        S = dot3(H, P, H.T) + dot(H, M) + dot(M.T, H.T) + R\n",
    "\n",
    "        mean = np.array(dot(H, x)).flatten()\n",
    "        flatz = np.array(z).flatten()\n",
    "\n",
    "        self.likelihood = multivariate_normal.pdf(flatz, mean, cov=S, allow_singular=True)\n",
    "        self.log_likelihood = multivariate_normal.logpdf(flatz, mean, cov=S, allow_singular=True)\n",
    "\n",
    "        # K = PH'inv(S)\n",
    "        # map system uncertainty into kalman gain\n",
    "        K = dot(dot(P, H.T) + M, linalg.inv(S))\n",
    "\n",
    "        # x = x + Ky\n",
    "        # predict new x with residual scaled by the kalman gain\n",
    "        self._x = x + dot(K, self._y)\n",
    "        self._P = P - dot(K, dot(H, P) + M.T)\n",
    "\n",
    "        self._S = S\n",
    "        self._K = K\n",
    "\n",
    "\n",
    "    def test_matrix_dimensions(self):\n",
    "        \"\"\" Performs a series of asserts to check that the size of everything\n",
    "        is what it should be. This can help you debug problems in your design.\n",
    "\n",
    "        This is only a test; you do not need to use it while filtering.\n",
    "        However, to use you will want to perform at least one predict() and\n",
    "        one update() before calling; some bad designs will cause the shapes\n",
    "        of x and P to change in a silent and bad way. For example, if you\n",
    "        pass in a badly dimensioned z into update that can cause x to be\n",
    "        misshapen.\"\"\"\n",
    "\n",
    "        assert self._x.shape == (self.dim_x, 1), \\\n",
    "               \"Shape of x must be ({},{}), but is {}\".format(\n",
    "               self.dim_x, 1, self._x.shape)\n",
    "\n",
    "        assert self._P.shape == (self.dim_x, self.dim_x), \\\n",
    "               \"Shape of P must be ({},{}), but is {}\".format(\n",
    "               self.dim_x, self.dim_x, self._P.shape)\n",
    "\n",
    "        assert self._Q.shape == (self.dim_x, self.dim_x), \\\n",
    "               \"Shape of P must be ({},{}), but is {}\".format(\n",
    "               self.dim_x, self.dim_x, self._P.shape)\n",
    "\n",
    "\n",
    "    def predict(self, u=0, B=None, F=None, Q=None):\n",
    "        \"\"\" Predict next position using the Kalman filter state propagation\n",
    "        equations.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        u : np.array\n",
    "            Optional control vector. If non-zero, it is multiplied by B\n",
    "            to create the control input into the system.\n",
    "\n",
    "        B : np.array(dim_x, dim_z), or None\n",
    "            Optional control transition matrix; a value of None in\n",
    "            any position will cause the filter to use `self.B`.\n",
    "\n",
    "        F : np.array(dim_x, dim_x), or None\n",
    "            Optional state transition matrix; a value of None in\n",
    "            any position will cause the filter to use `self.F`.\n",
    "\n",
    "        Q : np.array(dim_x, dim_x), scalar, or None\n",
    "            Optional process noise matrix; a value of None in\n",
    "            any position will cause the filter to use `self.Q`.\n",
    "        \"\"\"\n",
    "\n",
    "        if B is None:\n",
    "            B = self._B\n",
    "        if F is None:\n",
    "            F = self._F\n",
    "        if Q is None:\n",
    "            Q = self._Q\n",
    "        elif isscalar(Q):\n",
    "            Q = eye(self.dim_x) * Q\n",
    "\n",
    "        # x = Fx + Bu\n",
    "        self._x = dot(F, self.x) + dot(B, u)\n",
    "\n",
    "        # P = FPF' + Q\n",
    "        self._P = self._alpha_sq * dot3(F, self._P, F.T) + Q\n",
    "\n",
    "\n",
    "    def batch_filter(self, zs, Fs=None, Qs=None, Hs=None, Rs=None, Bs=None, us=None, update_first=False):\n",
    "        \"\"\" Batch processes a sequences of measurements.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        zs : list-like\n",
    "            list of measurements at each time step `self.dt` Missing\n",
    "            measurements must be represented by 'None'.\n",
    "\n",
    "        Fs : list-like, optional\n",
    "            optional list of values to use for the state transition matrix matrix;\n",
    "            a value of None in any position will cause the filter\n",
    "            to use `self.F` for that time step.\n",
    "\n",
    "        Qs : list-like, optional\n",
    "            optional list of values to use for the process error\n",
    "            covariance; a value of None in any position will cause the filter\n",
    "            to use `self.Q` for that time step.\n",
    "\n",
    "        Hs : list-like, optional\n",
    "            optional list of values to use for the measurement matrix;\n",
    "            a value of None in any position will cause the filter\n",
    "            to use `self.H` for that time step.\n",
    "\n",
    "        Rs : list-like, optional\n",
    "            optional list of values to use for the measurement error\n",
    "            covariance; a value of None in any position will cause the filter\n",
    "            to use `self.R` for that time step.\n",
    "\n",
    "        Bs : list-like, optional\n",
    "            optional list of values to use for the control transition matrix;\n",
    "            a value of None in any position will cause the filter\n",
    "            to use `self.B` for that time step.\n",
    "\n",
    "        us : list-like, optional\n",
    "            optional list of values to use for the control input vector;\n",
    "            a value of None in any position will cause the filter to use\n",
    "            0 for that time step.\n",
    "\n",
    "        update_first : bool, optional,\n",
    "            controls whether the order of operations is update followed by\n",
    "            predict, or predict followed by update. Default is predict->update.\n",
    "\n",
    "        **Returns**\n",
    "\n",
    "        means: np.array((n,dim_x,1))\n",
    "            array of the state for each time step after the update. Each entry\n",
    "            is an np.array. In other words `means[k,:]` is the state at step\n",
    "            `k`.\n",
    "\n",
    "        covariance: np.array((n,dim_x,dim_x))\n",
    "            array of the covariances for each time step after the update.\n",
    "            In other words `covariance[k,:,:]` is the covariance at step `k`.\n",
    "\n",
    "        means_predictions: np.array((n,dim_x,1))\n",
    "            array of the state for each time step after the predictions. Each\n",
    "            entry is an np.array. In other words `means[k,:]` is the state at\n",
    "            step `k`.\n",
    "\n",
    "        covariance_predictions: np.array((n,dim_x,dim_x))\n",
    "            array of the covariances for each time step after the prediction.\n",
    "            In other words `covariance[k,:,:]` is the covariance at step `k`.\n",
    "\n",
    "        **Example**\n",
    "\n",
    "        zs = [t + random.randn()*4 for t in range (40)]\n",
    "        Fs = [kf.F for t in range (40)]\n",
    "        Hs = [kf.H for t in range (40)]\n",
    "\n",
    "        (mu, cov, _, _) = kf.batch_filter(zs, Rs=R_list, Fs=Fs, Hs=Hs, Qs=None,\n",
    "                                          Bs=None, us=None, update_first=False)\n",
    "        (xs, Ps, Ks) = kf.rts_smoother(mu, cov, Fs=Fs, Qs=None)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n = np.size(zs,0)\n",
    "        if Fs is None:\n",
    "            Fs = [self.F] * n\n",
    "        if Qs is None:\n",
    "            Qs = [self.Q] * n\n",
    "        if Hs is None:\n",
    "            Hs = [self.H] * n\n",
    "        if Rs is None:\n",
    "            Rs = [self.R] * n\n",
    "        if Bs is None:\n",
    "            Bs = [self.B] * n\n",
    "        if us is None:\n",
    "            us = [0] * n\n",
    "\n",
    "        # mean estimates from Kalman Filter\n",
    "        if self.x.ndim == 1:\n",
    "            means   = zeros((n, self.dim_x))\n",
    "            means_p = zeros((n, self.dim_x))\n",
    "        else:\n",
    "            means   = zeros((n, self.dim_x, 1))\n",
    "            means_p = zeros((n, self.dim_x, 1))\n",
    "\n",
    "        # state covariances from Kalman Filter\n",
    "        covariances   = zeros((n, self.dim_x, self.dim_x))\n",
    "        covariances_p = zeros((n, self.dim_x, self.dim_x))\n",
    "\n",
    "        if update_first:\n",
    "            for i, (z, F, Q, H, R, B, u) in enumerate(zip(zs, Fs, Qs, Hs, Rs, Bs, us)):\n",
    "\n",
    "                self.update(z, R=R, H=H)\n",
    "                means[i,:]         = self._x\n",
    "                covariances[i,:,:] = self._P\n",
    "\n",
    "                self.predict(u=u, B=B, F=F, Q=Q)\n",
    "                means_p[i,:]         = self._x\n",
    "                covariances_p[i,:,:] = self._P\n",
    "        else:\n",
    "            for i, (z, F, Q, H, R, B, u) in enumerate(zip(zs, Fs, Qs, Hs, Rs, Bs, us)):\n",
    "\n",
    "                self.predict(u=u, B=B, F=F, Q=Q)\n",
    "                means_p[i,:]         = self._x\n",
    "                covariances_p[i,:,:] = self._P\n",
    "\n",
    "                self.update(z, R=R, H=H)\n",
    "                means[i,:]         = self._x\n",
    "                covariances[i,:,:] = self._P\n",
    "\n",
    "        return (means, covariances, means_p, covariances_p)\n",
    "\n",
    "\n",
    "\n",
    "    def rts_smoother(self, Xs, Ps, Fs=None, Qs=None):\n",
    "        \"\"\" Runs the Rauch-Tung-Striebal Kalman smoother on a set of\n",
    "        means and covariances computed by a Kalman filter. The usual input\n",
    "        would come from the output of `KalmanFilter.batch_filter()`.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        Xs : numpy.array\n",
    "           array of the means (state variable x) of the output of a Kalman\n",
    "           filter.\n",
    "\n",
    "        Ps : numpy.array\n",
    "            array of the covariances of the output of a kalman filter.\n",
    "\n",
    "        Fs : list-like collection of numpy.array, optional\n",
    "            State transition matrix of the Kalman filter at each time step. \n",
    "            Optional, if not provided the filter's self.F will be used\n",
    "\n",
    "        Qs : list-like collection of numpy.array, optional\n",
    "            Process noise of the Kalman filter at each time step. Optional,\n",
    "            if not provided the filter's self.Q will be used\n",
    "\n",
    "        **Returns**\n",
    "\n",
    "        'x' : numpy.ndarray\n",
    "           smoothed means\n",
    "\n",
    "        'P' : numpy.ndarray\n",
    "           smoothed state covariances\n",
    "\n",
    "        'K' : numpy.ndarray\n",
    "            smoother gain at each step\n",
    "\n",
    "\n",
    "        **Example**::\n",
    "\n",
    "            zs = [t + random.randn()*4 for t in range (40)]\n",
    "\n",
    "            (mu, cov, _, _) = kalman.batch_filter(zs)\n",
    "            (x, P, K) = rts_smoother(mu, cov, kf.F, kf.Q)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        assert len(Xs) == len(Ps)\n",
    "        shape = Xs.shape\n",
    "        n = shape[0]\n",
    "        dim_x = shape[1]\n",
    "\n",
    "        if Fs is None:\n",
    "            Fs = [self.F] * n\n",
    "        if Qs is None:\n",
    "            Qs = [self.Q] * n\n",
    "\n",
    "        # smoother gain\n",
    "        K = zeros((n,dim_x,dim_x))\n",
    "\n",
    "        x, P = Xs.copy(), Ps.copy()\n",
    "\n",
    "        for k in range(n-2,-1,-1):\n",
    "            P_pred = dot3(Fs[k], P[k], Fs[k].T) + Qs[k]\n",
    "\n",
    "            K[k]  = dot3(P[k], Fs[k].T, linalg.inv(P_pred))\n",
    "            x[k] += dot (K[k], x[k+1] - dot(Fs[k], x[k]))\n",
    "            P[k] += dot3 (K[k], P[k+1] - P_pred, K[k].T)\n",
    "\n",
    "        return (x, P, K)\n",
    "\n",
    "\n",
    "    def get_prediction(self, u=0):\n",
    "        \"\"\" Predicts the next state of the filter and returns it. Does not\n",
    "        alter the state of the filter.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        u : np.array\n",
    "            optional control input\n",
    "\n",
    "        **Returns**\n",
    "\n",
    "        (x, P)\n",
    "            State vector and covariance array of the prediction.\n",
    "        \"\"\"\n",
    "\n",
    "        x = dot(self._F, self._x) + dot(self._B, u)\n",
    "        P = self._alpha_sq * dot3(self._F, self._P, self._F.T) + self._Q\n",
    "        return (x, P)\n",
    "\n",
    "\n",
    "    def residual_of(self, z):\n",
    "        \"\"\" returns the residual for the given measurement (z). Does not alter\n",
    "        the state of the filter.\n",
    "        \"\"\"\n",
    "        return z - dot(self.H, self._x)\n",
    "\n",
    "\n",
    "    def measurement_of_state(self, x):\n",
    "        \"\"\" Helper function that converts a state into a measurement.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        x : np.array\n",
    "            kalman state vector\n",
    "\n",
    "        **Returns**\n",
    "\n",
    "        z : np.array\n",
    "            measurement corresponding to the given state\n",
    "        \"\"\"\n",
    "\n",
    "        return dot(self.H, x)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        \"\"\" Fading memory setting. 1.0 gives the normal Kalman filter, and\n",
    "        values slightly larger than 1.0 (such as 1.02) give a fading\n",
    "        memory effect - previous measurements have less influence on the\n",
    "        filter's estimates. This formulation of the Fading memory filter\n",
    "        (there are many) is due to Dan Simon [1].\n",
    "\n",
    "        ** References **\n",
    "\n",
    "        [1] Dan Simon. \"Optimal State Estimation.\" John Wiley & Sons.\n",
    "            p. 208-212. (2006)\n",
    "        \"\"\"\n",
    "\n",
    "        return self._alpha_sq**.5\n",
    "\n",
    "\n",
    "    @alpha.setter\n",
    "    def alpha(self, value):\n",
    "        assert np.isscalar(value)\n",
    "        assert value > 0\n",
    "\n",
    "        self._alpha_sq = value**2\n",
    "\n",
    "    @property\n",
    "    def Q(self):\n",
    "        \"\"\" Process uncertainty\"\"\"\n",
    "        return self._Q\n",
    "\n",
    "\n",
    "    @Q.setter\n",
    "    def Q(self, value):\n",
    "        self._Q = setter_scalar(value, self.dim_x)\n",
    "\n",
    "    @property\n",
    "    def P(self):\n",
    "        \"\"\" covariance matrix\"\"\"\n",
    "        return self._P\n",
    "\n",
    "\n",
    "    @P.setter\n",
    "    def P(self, value):\n",
    "        self._P = setter_scalar(value, self.dim_x)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def F(self):\n",
    "        \"\"\" state transition matrix\"\"\"\n",
    "        return self._F\n",
    "\n",
    "\n",
    "    @F.setter\n",
    "    def F(self, value):\n",
    "        self._F = setter(value, self.dim_x, self.dim_x)\n",
    "\n",
    "    @property\n",
    "    def B(self):\n",
    "        \"\"\" control transition matrix\"\"\"\n",
    "        return self._B\n",
    "\n",
    "\n",
    "    @B.setter\n",
    "    def B(self, value):\n",
    "        self._B = value\n",
    "        \"\"\" control transition matrix\"\"\"\n",
    "        if np.isscalar(value):\n",
    "            self._B = value\n",
    "        else:\n",
    "            self._B = setter (value, self.dim_x, self.dim_u)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        \"\"\" filter state vector.\"\"\"\n",
    "        return self._x\n",
    "\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, value):\n",
    "        self._x = setter_1d(value, self.dim_x)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def K(self):\n",
    "        \"\"\" Kalman gain \"\"\"\n",
    "        return self._K\n",
    "\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        \"\"\" measurement residual (innovation) \"\"\"\n",
    "        return self._y\n",
    "\n",
    "    @property\n",
    "    def S(self):\n",
    "        \"\"\" system uncertainty in measurement space \"\"\"\n",
    "        return self._S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtendedKalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/rlabbe/filterpy/master/filterpy/kalman/EKF.py\n",
    "\n",
    "\"\"\"Copyright 2015 Roger R Labbe Jr.\n",
    "\n",
    "FilterPy library.\n",
    "http://github.com/rlabbe/filterpy\n",
    "\n",
    "Documentation at:\n",
    "https://filterpy.readthedocs.org\n",
    "\n",
    "Supporting book at:\n",
    "https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python\n",
    "\n",
    "This is licensed under an MIT license. See the readme.MD file\n",
    "for more information.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "from numpy import dot, zeros, eye\n",
    "from filterpy.common import setter, setter_1d, setter_scalar, dot3\n",
    "\n",
    "\n",
    "class ExtendedKalmanFilter(object):\n",
    "\n",
    "    def __init__(self, dim_x, dim_z, dim_u=0):\n",
    "        \"\"\" Extended Kalman filter. You are responsible for setting the\n",
    "        various state variables to reasonable values; the defaults below will\n",
    "        not give you a functional filter.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        dim_x : int\n",
    "            Number of state variables for the Kalman filter. For example, if\n",
    "            you are tracking the position and velocity of an object in two\n",
    "            dimensions, dim_x would be 4.\n",
    "\n",
    "            This is used to set the default size of P, Q, and u\n",
    "\n",
    "        dim_z : int\n",
    "            Number of of measurement inputs. For example, if the sensor\n",
    "            provides you with position in (x,y), dim_z would be 2.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_z = dim_z\n",
    "\n",
    "        self._x = zeros((dim_x,1)) # state\n",
    "        self._P = eye(dim_x)       # uncertainty covariance\n",
    "        self._B = 0                # control transition matrix\n",
    "        self._F = 0                # state transition matrix\n",
    "        self._R = eye(dim_z)       # state uncertainty\n",
    "        self._Q = eye(dim_x)       # process uncertainty\n",
    "        self._y = zeros((dim_z, 1))\n",
    "\n",
    "        # identity matrix. Do not alter this.\n",
    "        self._I = np.eye(dim_x)\n",
    "\n",
    "\n",
    "    def predict_update(self, z, HJacobian, Hx, args=(), hx_args=(), u=0):\n",
    "        \"\"\" Performs the predict/update innovation of the extended Kalman\n",
    "        filter.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        z : np.array\n",
    "            measurement for this step.\n",
    "            If `None`, only predict step is perfomed.\n",
    "\n",
    "        HJacobian : function\n",
    "           function which computes the Jacobian of the H matrix (measurement\n",
    "           function). Takes state variable (self.x) as input, along with the\n",
    "           optional arguments in args, and returns H.\n",
    "\n",
    "        Hx : function\n",
    "            function which takes as input the state variable (self.x) along\n",
    "            with the optional arguments in hx_args, and returns the measurement\n",
    "            that would correspond to that state.\n",
    "\n",
    "        args : tuple, optional, default (,)\n",
    "            arguments to be passed into HJacobian after the required state\n",
    "            variable.\n",
    "\n",
    "        hx_args : tuple, optional, default (,)\n",
    "            arguments to be passed into HJacobian after the required state\n",
    "            variable.\n",
    "\n",
    "        u : np.array or scalar\n",
    "            optional control vector input to the filter.\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(args, tuple):\n",
    "            args = (args,)\n",
    "\n",
    "        if not isinstance(hx_args, tuple):\n",
    "            hx_args = (hx_args,)\n",
    "\n",
    "        if np.isscalar(z) and self.dim_z == 1:\n",
    "            z = np.asarray([z], float)\n",
    "\n",
    "        F = self._F\n",
    "        B = self._B\n",
    "        P = self._P\n",
    "        Q = self._Q\n",
    "        R = self._R\n",
    "        x = self._x\n",
    "\n",
    "        H = HJacobian(x, *args)\n",
    "\n",
    "        # predict step\n",
    "        x = dot(F, x) + dot(B, u)\n",
    "        P = dot3(F, P, F.T) + Q\n",
    "\n",
    "        # update step\n",
    "        S = dot3(H, P, H.T) + R\n",
    "        K = dot3(P, H.T, linalg.inv (S))\n",
    "\n",
    "        self._x = x + dot(K, (z - Hx(x, *hx_args)))\n",
    "\n",
    "        I_KH = self._I - dot(K, H)\n",
    "        self._P = dot3(I_KH, P, I_KH.T) + dot3(K, R, K.T)\n",
    "\n",
    "\n",
    "    def update(self, z, HJacobian, Hx, R=None, args=(), hx_args=(),\n",
    "               residual=np.subtract):\n",
    "        \"\"\" Performs the update innovation of the extended Kalman filter.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        z : np.array\n",
    "            measurement for this step.\n",
    "            If `None`, only predict step is perfomed.\n",
    "\n",
    "        HJacobian : function\n",
    "           function which computes the Jacobian of the H matrix (measurement\n",
    "           function). Takes state variable (self.x) as input, returns H.\n",
    "\n",
    "        Hx : function\n",
    "            function which takes as input the state variable (self.x) along\n",
    "            with the optional arguments in hx_args, and returns the measurement\n",
    "            that would correspond to that state.\n",
    "\n",
    "        R : np.array, scalar, or None\n",
    "            Optionally provide R to override the measurement noise for this\n",
    "            one call, otherwise  self.R will be used.\n",
    "\n",
    "        args : tuple, optional, default (,)\n",
    "            arguments to be passed into HJacobian after the required state\n",
    "            variable. for robot localization you might need to pass in\n",
    "            information about the map and time of day, so you might have\n",
    "            `args=(map_data, time)`, where the signature of HCacobian will\n",
    "            be `def HJacobian(x, map, t)`\n",
    "\n",
    "        hx_args : tuple, optional, default (,)\n",
    "            arguments to be passed into Hx function after the required state\n",
    "            variable.\n",
    "\n",
    "        residual : function (z, z2), optional\n",
    "            Optional function that computes the residual (difference) between\n",
    "            the two measurement vectors. If you do not provide this, then the\n",
    "            built in minus operator will be used. You will normally want to use\n",
    "            the built in unless your residual computation is nonlinear (for\n",
    "            example, if they are angles)\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(args, tuple):\n",
    "            args = (args,)\n",
    "\n",
    "        if not isinstance(hx_args, tuple):\n",
    "            hx_args = (hx_args,)\n",
    "\n",
    "        P = self._P\n",
    "        if R is None:\n",
    "            R = self._R\n",
    "        elif np.isscalar(R):\n",
    "            R = eye(self.dim_z) * R\n",
    "\n",
    "        if np.isscalar(z) and self.dim_z == 1:\n",
    "            z = np.asarray([z], float)\n",
    "\n",
    "        x = self._x\n",
    "\n",
    "        H = HJacobian(x, *args)\n",
    "\n",
    "        S = dot3(H, P, H.T) + R\n",
    "        K = dot3(P, H.T, linalg.inv (S))\n",
    "\n",
    "        hx =  Hx(x, *hx_args)\n",
    "        y = residual(z, hx)\n",
    "        self._x = x + dot(K, y)\n",
    "\n",
    "        I_KH = self._I - dot(K, H)\n",
    "        self._P = dot3(I_KH, P, I_KH.T) + dot3(K, R, K.T)\n",
    "\n",
    "\n",
    "    def predict_x(self, u=0):\n",
    "        \"\"\" predicts the next state of X. If you need to\n",
    "        compute the next state yourself, override this function. You would\n",
    "        need to do this, for example, if the usual Taylor expansion to\n",
    "        generate F is not providing accurate results for you. \"\"\"\n",
    "\n",
    "        self._x = dot(self._F, self._x) + dot(self._B, u)\n",
    "\n",
    "\n",
    "    def predict(self, u=0):\n",
    "        \"\"\" Predict next position.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        u : np.array\n",
    "            Optional control vector. If non-zero, it is multiplied by B\n",
    "            to create the control input into the system.\n",
    "        \"\"\"\n",
    "\n",
    "        self.predict_x(u)\n",
    "        self._P = dot3(self._F, self._P, self._F.T) + self._Q\n",
    "\n",
    "\n",
    "    @property\n",
    "    def Q(self):\n",
    "        \"\"\" Process uncertainty\"\"\"\n",
    "        return self._Q\n",
    "\n",
    "\n",
    "    @Q.setter\n",
    "    def Q(self, value):\n",
    "        self._Q = setter_scalar(value, self.dim_x)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def P(self):\n",
    "        \"\"\" covariance matrix\"\"\"\n",
    "        return self._P\n",
    "\n",
    "\n",
    "    @P.setter\n",
    "    def P(self, value):\n",
    "        self._P = setter_scalar(value, self.dim_x)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def R(self):\n",
    "        \"\"\" measurement uncertainty\"\"\"\n",
    "        return self._R\n",
    "\n",
    "\n",
    "    @R.setter\n",
    "    def R(self, value):\n",
    "        self._R = setter_scalar(value, self.dim_z)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def F(self):\n",
    "        return self._F\n",
    "\n",
    "\n",
    "    @F.setter\n",
    "    def F(self, value):\n",
    "        self._F = setter(value, self.dim_x, self.dim_x)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def B(self):\n",
    "        return self._B\n",
    "\n",
    "\n",
    "    @B.setter\n",
    "    def B(self, value):\n",
    "        \"\"\" control transition matrix\"\"\"\n",
    "        self._B = setter(value, self.dim_x, self.dim_u)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._x\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, value):\n",
    "        self._x = setter_1d(value, self.dim_x)\n",
    "\n",
    "    @property\n",
    "    def K(self):\n",
    "        \"\"\" Kalman gain \"\"\"\n",
    "        return self._K\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        \"\"\" measurement residual (innovation) \"\"\"\n",
    "        return self._y\n",
    "\n",
    "    @property\n",
    "    def S(self):\n",
    "        \"\"\" system uncertainty in measurement space \"\"\"\n",
    "        return self._S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UnscentedKalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/rlabbe/filterpy/master/filterpy/kalman/UKF.py\n",
    "\"\"\"Copyright 2015 Roger R Labbe Jr.\n",
    "\n",
    "FilterPy library.\n",
    "http://github.com/rlabbe/filterpy\n",
    "\n",
    "Documentation at:\n",
    "https://filterpy.readthedocs.org\n",
    "\n",
    "Supporting book at:\n",
    "https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python\n",
    "\n",
    "This is licensed under an MIT license. See the readme.MD file\n",
    "for more information.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "from filterpy.common import dot3\n",
    "from filterpy.kalman import unscented_transform\n",
    "import numpy as np\n",
    "from numpy import eye, zeros, dot, isscalar, outer\n",
    "from scipy.linalg import inv, cholesky\n",
    "\n",
    "\n",
    "class UnscentedKalmanFilter(object):\n",
    "    # pylint: disable=too-many-instance-attributes\n",
    "    # pylint: disable=C0103\n",
    "    r\"\"\" Implements the Scaled Unscented Kalman filter (UKF) as defined by\n",
    "    Simon Julier in [1], using the formulation provided by Wan and Merle\n",
    "    in [2]. This filter scales the sigma points to avoid strong nonlinearities.\n",
    "\n",
    "\n",
    "    You will have to set the following attributes after constructing this\n",
    "    object for the filter to perform properly.\n",
    "\n",
    "    **Attributes**\n",
    "\n",
    "    x : numpy.array(dim_x)\n",
    "        state estimate vector\n",
    "\n",
    "    P : numpy.array(dim_x, dim_x)\n",
    "        covariance estimate matrix\n",
    "\n",
    "    R : numpy.array(dim_z, dim_z)\n",
    "        measurement noise matrix\n",
    "\n",
    "    Q : numpy.array(dim_x, dim_x)\n",
    "        process noise matrix\n",
    "\n",
    "\n",
    "    You may read the following attributes.\n",
    "\n",
    "    **Readable Attributes**\n",
    "\n",
    "    xp : numpy.array(dim_x)\n",
    "        predicted state (result of predict())\n",
    "\n",
    "    Pp : numpy.array(dim_x, dim_x)\n",
    "        predicted covariance matrix (result of predict())\n",
    "\n",
    "\n",
    "    **References**\n",
    "\n",
    "    .. [1] Julier, Simon J. \"The scaled unscented transformation,\"\n",
    "        American Control Converence, 2002, pp 4555-4559, vol 6.\n",
    "\n",
    "        Online copy:\n",
    "        https://www.cs.unc.edu/~welch/kalman/media/pdf/ACC02-IEEE1357.PDF\n",
    "\n",
    "\n",
    "    .. [2] E. A. Wan and R. Van der Merwe, “The unscented Kalman filter for\n",
    "        nonlinear estimation,” in Proc. Symp. Adaptive Syst. Signal\n",
    "        Process., Commun. Contr., Lake Louise, AB, Canada, Oct. 2000.\n",
    "\n",
    "        Online Copy:\n",
    "        https://www.seas.harvard.edu/courses/cs281/papers/unscented.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim_x, dim_z, dt, hx, fx, points,\n",
    "                 sqrt_fn=None, x_mean_fn=None, z_mean_fn=None,\n",
    "                 residual_x=None,\n",
    "                 residual_z=None):\n",
    "        r\"\"\" Create a Kalman filter. You are responsible for setting the\n",
    "        various state variables to reasonable values; the defaults below will\n",
    "        not give you a functional filter.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        dim_x : int\n",
    "            Number of state variables for the filter. For example, if\n",
    "            you are tracking the position and velocity of an object in two\n",
    "            dimensions, dim_x would be 4.\n",
    "\n",
    "\n",
    "        dim_z : int\n",
    "            Number of of measurement inputs. For example, if the sensor\n",
    "            provides you with position in (x,y), dim_z would be 2.\n",
    "\n",
    "        dt : float\n",
    "            Time between steps in seconds.\n",
    "\n",
    "        hx : function(x)\n",
    "            Measurement function. Converts state vector x into a measurement\n",
    "            vector of shape (dim_z).\n",
    "\n",
    "        fx : function(x,dt)\n",
    "            function that returns the state x transformed by the\n",
    "            state transistion function. dt is the time step in seconds.\n",
    "\n",
    "        points : class\n",
    "            Class which computes the sigma points and weights for a UKF\n",
    "            algorithm. You can vary the UKF implementation by changing this\n",
    "            class. For example, MerweScaledSigmaPoints implements the alpha,\n",
    "            beta, kappa parameterization of Van der Merwe, and\n",
    "            JulierSigmaPoints implements Julier's original kappa\n",
    "            parameterization. See either of those for the required\n",
    "            signature of this class if you want to implement your own.\n",
    "\n",
    "        sqrt_fn : callable(ndarray), default = scipy.linalg.cholesky\n",
    "            Defines how we compute the square root of a matrix, which has\n",
    "            no unique answer. Cholesky is the default choice due to its\n",
    "            speed. Typically your alternative choice will be\n",
    "            scipy.linalg.sqrtm. Different choices affect how the sigma points\n",
    "            are arranged relative to the eigenvectors of the covariance matrix.\n",
    "            Usually this will not matter to you; if so the default cholesky()\n",
    "            yields maximal performance. As of van der Merwe's dissertation of\n",
    "            2004 [6] this was not a well reseached area so I have no advice\n",
    "            to give you.\n",
    "\n",
    "            If your method returns a triangular matrix it must be upper\n",
    "            triangular. Do not use numpy.linalg.cholesky - for historical\n",
    "            reasons it returns a lower triangular matrix. The SciPy version\n",
    "            does the right thing.\n",
    "\n",
    "        x_mean_fn : callable  (sigma_points, weights), optional\n",
    "            Function that computes the mean of the provided sigma points\n",
    "            and weights. Use this if your state variable contains nonlinear\n",
    "            values such as angles which cannot be summed.\n",
    "\n",
    "            .. code-block:: Python\n",
    "\n",
    "                def state_mean(sigmas, Wm):\n",
    "                    x = np.zeros(3)\n",
    "                    sum_sin, sum_cos = 0., 0.\n",
    "\n",
    "                    for i in range(len(sigmas)):\n",
    "                        s = sigmas[i]\n",
    "                        x[0] += s[0] * Wm[i]\n",
    "                        x[1] += s[1] * Wm[i]\n",
    "                        sum_sin += sin(s[2])*Wm[i]\n",
    "                        sum_cos += cos(s[2])*Wm[i]\n",
    "                    x[2] = atan2(sum_sin, sum_cos)\n",
    "                    return x\n",
    "\n",
    "        z_mean_fn : callable  (sigma_points, weights), optional\n",
    "            Same as x_mean_fn, except it is called for sigma points which\n",
    "            form the measurements after being passed through hx().\n",
    "\n",
    "        residual_x : callable (x, y), optional\n",
    "        residual_z : callable (x, y), optional\n",
    "            Function that computes the residual (difference) between x and y.\n",
    "            You will have to supply this if your state variable cannot support\n",
    "            subtraction, such as angles (359-1 degreees is 2, not 358). x and y\n",
    "            are state vectors, not scalars. One is for the state variable,\n",
    "            the other is for the measurement state.\n",
    "\n",
    "            .. code-block:: Python\n",
    "\n",
    "                def residual(a, b):\n",
    "                    y = a[0] - b[0]\n",
    "                    if y > np.pi:\n",
    "                        y -= 2*np.pi\n",
    "                    if y < -np.pi:\n",
    "                        y = 2*np.pi\n",
    "                    return y\n",
    "\n",
    "        **References**\n",
    "\n",
    "        .. [3] S. Julier, J. Uhlmann, and H. Durrant-Whyte. \"A new method for\n",
    "               the nonlinear transformation of means and covariances in filters\n",
    "               and estimators,\" IEEE Transactions on Automatic Control, 45(3),\n",
    "               pp. 477-482 (March 2000).\n",
    "\n",
    "        .. [4] E. A. Wan and R. Van der Merwe, “The Unscented Kalman filter for\n",
    "               Nonlinear Estimation,” in Proc. Symp. Adaptive Syst. Signal\n",
    "               Process., Commun. Contr., Lake Louise, AB, Canada, Oct. 2000.\n",
    "\n",
    "               https://www.seas.harvard.edu/courses/cs281/papers/unscented.pdf\n",
    "\n",
    "        .. [5] Wan, Merle \"The Unscented Kalman Filter,\" chapter in *Kalman\n",
    "               Filtering and Neural Networks*, John Wiley & Sons, Inc., 2001.\n",
    "\n",
    "        .. [6] R. Van der Merwe \"Sigma-Point Kalman Filters for Probabilitic\n",
    "               Inference in Dynamic State-Space Models\" (Doctoral dissertation)\n",
    "        \"\"\"\n",
    "\n",
    "        self.Q = eye(dim_x)\n",
    "        self.R = eye(dim_z)\n",
    "        self.x = zeros(dim_x)\n",
    "        self.P = eye(dim_x)\n",
    "        self._dim_x = dim_x\n",
    "        self._dim_z = dim_z\n",
    "        self._dt = dt\n",
    "        self._num_sigmas = 2*dim_x + 1\n",
    "        self.hx = hx\n",
    "        self.fx = fx\n",
    "        self.points_fn = points\n",
    "        self.x_mean = x_mean_fn\n",
    "        self.z_mean = z_mean_fn\n",
    "\n",
    "        if sqrt_fn is None:\n",
    "            self.msqrt = cholesky\n",
    "        else:\n",
    "            self.msqrt = sqrt_fn\n",
    "\n",
    "        # weights for the means and covariances.\n",
    "        self.Wm, self.Wc = self.points_fn.weights()\n",
    "\n",
    "        if residual_x is None:\n",
    "            self.residual_x = np.subtract\n",
    "        else:\n",
    "            self.residual_x = residual_x\n",
    "\n",
    "        if residual_z is None:\n",
    "            self.residual_z = np.subtract\n",
    "        else:\n",
    "            self.residual_z = residual_z\n",
    "\n",
    "        # sigma points transformed through f(x) and h(x)\n",
    "        # variables for efficiency so we don't recreate every update\n",
    "        self.sigmas_f = zeros((2*self._dim_x+1, self._dim_x))\n",
    "        self.sigmas_h = zeros((self._num_sigmas, self._dim_z))\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, dt=None,  UT=None, fx_args=()):\n",
    "        r\"\"\" Performs the predict step of the UKF. On return, self.x and\n",
    "        self.P contain the predicted state (x) and covariance (P). '\n",
    "\n",
    "        Important: this MUST be called before update() is called for the first\n",
    "        time.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        dt : double, optional\n",
    "            If specified, the time step to be used for this prediction.\n",
    "            self._dt is used if this is not provided.\n",
    "\n",
    "        UT : function(sigmas, Wm, Wc, noise_cov), optional\n",
    "            Optional function to compute the unscented transform for the sigma\n",
    "            points passed through hx. Typically the default function will\n",
    "            work - you can use x_mean_fn and z_mean_fn to alter the behavior\n",
    "            of the unscented transform.\n",
    "\n",
    "        fx_args : tuple, optional, default (,)\n",
    "            optional arguments to be passed into fx() after the required state\n",
    "            variable.\n",
    "\n",
    "        \"\"\"\n",
    "        if dt is None:\n",
    "            dt = self._dt\n",
    "\n",
    "        if not isinstance(fx_args, tuple):\n",
    "            fx_args = (fx_args,)\n",
    "\n",
    "        if UT is None:\n",
    "            UT = unscented_transform\n",
    "\n",
    "        # calculate sigma points for given mean and covariance\n",
    "        sigmas = self.points_fn.sigma_points(self.x, self.P)\n",
    "\n",
    "        for i in range(self._num_sigmas):\n",
    "            self.sigmas_f[i] = self.fx(sigmas[i], dt, *fx_args)\n",
    "\n",
    "        self.x, self.P = UT(self.sigmas_f, self.Wm, self.Wc, self.Q,\n",
    "                            self.x_mean, self.residual_x)\n",
    "\n",
    "\n",
    "    def update(self, z, R=None, UT=None, hx_args=()):\n",
    "        \"\"\" Update the UKF with the given measurements. On return,\n",
    "        self.x and self.P contain the new mean and covariance of the filter.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        z : numpy.array of shape (dim_z)\n",
    "            measurement vector\n",
    "\n",
    "        R : numpy.array((dim_z, dim_z)), optional\n",
    "            Measurement noise. If provided, overrides self.R for\n",
    "            this function call.\n",
    "\n",
    "        UT : function(sigmas, Wm, Wc, noise_cov), optional\n",
    "            Optional function to compute the unscented transform for the sigma\n",
    "            points passed through hx. Typically the default function will\n",
    "            work - you can use x_mean_fn and z_mean_fn to alter the behavior\n",
    "            of the unscented transform.\n",
    "\n",
    "        hx_args : tuple, optional, default (,)\n",
    "            arguments to be passed into Hx function after the required state\n",
    "            variable.\n",
    "        \"\"\"\n",
    "\n",
    "        if z is None:\n",
    "            return\n",
    "\n",
    "        if not isinstance(hx_args, tuple):\n",
    "            hx_args = (hx_args,)\n",
    "\n",
    "        if UT is None:\n",
    "            UT = unscented_transform\n",
    "\n",
    "        if R is None:\n",
    "            R = self.R\n",
    "        elif isscalar(R):\n",
    "            R = eye(self._dim_z) * R\n",
    "\n",
    "        for i in range(self._num_sigmas):\n",
    "            self.sigmas_h[i] = self.hx(self.sigmas_f[i], *hx_args)\n",
    "\n",
    "        # mean and covariance of prediction passed through unscented transform\n",
    "        zp, Pz = UT(self.sigmas_h, self.Wm, self.Wc, R, self.z_mean, self.residual_z)\n",
    "\n",
    "        # compute cross variance of the state and the measurements\n",
    "        Pxz = zeros((self._dim_x, self._dim_z))\n",
    "        for i in range(self._num_sigmas):\n",
    "            dx = self.residual_x(self.sigmas_f[i], self.x)\n",
    "            dz =  self.residual_z(self.sigmas_h[i], zp)\n",
    "            Pxz += self.Wc[i] * outer(dx, dz)\n",
    "\n",
    "        K = dot(Pxz, inv(Pz))   # Kalman gain\n",
    "        y = self.residual_z(z, zp)   #residual\n",
    "        self.x = self.x + dot(K, y)\n",
    "        self.P = self.P - dot3(K, Pz, K.T)\n",
    "\n",
    "\n",
    "    def batch_filter(self, zs, Rs=None, residual=None, UT=None):\n",
    "        \"\"\" Performs the UKF filter over the list of measurement in `zs`.\n",
    "\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        zs : list-like\n",
    "            list of measurements at each time step `self._dt` Missing\n",
    "            measurements must be represented by 'None'.\n",
    "\n",
    "        Rs : list-like, optional\n",
    "            optional list of values to use for the measurement error\n",
    "            covariance; a value of None in any position will cause the filter\n",
    "            to use `self.R` for that time step.\n",
    "\n",
    "        residual : function (z, z2), optional\n",
    "            Optional function that computes the residual (difference) between\n",
    "            the two measurement vectors. If you do not provide this, then the\n",
    "            built in minus operator will be used. You will normally want to use\n",
    "            the built in unless your residual computation is nonlinear (for\n",
    "            example, if they are angles)\n",
    "\n",
    "        UT : function(sigmas, Wm, Wc, noise_cov), optional\n",
    "            Optional function to compute the unscented transform for the sigma\n",
    "            points passed through hx. Typically the default function will\n",
    "            work - you can use x_mean_fn and z_mean_fn to alter the behavior\n",
    "            of the unscented transform.\n",
    "\n",
    "        **Returns**\n",
    "\n",
    "        means: ndarray((n,dim_x,1))\n",
    "            array of the state for each time step after the update. Each entry\n",
    "            is an np.array. In other words `means[k,:]` is the state at step\n",
    "            `k`.\n",
    "\n",
    "        covariance: ndarray((n,dim_x,dim_x))\n",
    "            array of the covariances for each time step after the update.\n",
    "            In other words `covariance[k,:,:]` is the covariance at step `k`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            z = zs[0]\n",
    "        except:\n",
    "            assert not isscalar(zs), 'zs must be list-like'\n",
    "\n",
    "        if self._dim_z == 1:\n",
    "            assert isscalar(z) or (z.ndim==1 and len(z) == 1), \\\n",
    "            'zs must be a list of scalars or 1D, 1 element arrays'\n",
    "\n",
    "        else:\n",
    "            assert len(z) == self._dim_z, 'each element in zs must be a' \\\n",
    "            '1D array of length {}'.format(self._dim_z)\n",
    "\n",
    "\n",
    "        if residual is None:\n",
    "            residual = np.subtract\n",
    "\n",
    "        z_n = np.size(zs, 0)\n",
    "        if Rs is None:\n",
    "            Rs = [None] * z_n\n",
    "\n",
    "        # mean estimates from Kalman Filter\n",
    "        if self.x.ndim == 1:\n",
    "            means = zeros((z_n, self._dim_x))\n",
    "        else:\n",
    "            means = zeros((z_n, self._dim_x, 1))\n",
    "\n",
    "        # state covariances from Kalman Filter\n",
    "        covariances = zeros((z_n, self._dim_x, self._dim_x))\n",
    "\n",
    "        for i, (z, r) in enumerate(zip(zs, Rs)):\n",
    "            self.predict()\n",
    "            self.update(z, r)\n",
    "            means[i,:]         = self.x\n",
    "            covariances[i,:,:] = self.P\n",
    "\n",
    "        return (means, covariances)\n",
    "\n",
    "\n",
    "    def rts_smoother(self, Xs, Ps, Qs=None, dt=None):\n",
    "        \"\"\" Runs the Rauch-Tung-Striebal Kalman smoother on a set of\n",
    "        means and covariances computed by the UKF. The usual input\n",
    "        would come from the output of `batch_filter()`.\n",
    "\n",
    "        **Parameters**\n",
    "\n",
    "        Xs : numpy.array\n",
    "           array of the means (state variable x) of the output of a Kalman\n",
    "           filter.\n",
    "\n",
    "        Ps : numpy.array\n",
    "            array of the covariances of the output of a kalman filter.\n",
    "\n",
    "        Qs: list-like collection of numpy.array, optional\n",
    "            Process noise of the Kalman filter at each time step. Optional,\n",
    "            if not provided the filter's self.Q will be used\n",
    "\n",
    "        dt : optional, float or array-like of float\n",
    "            If provided, specifies the time step of each step of the filter.\n",
    "            If float, then the same time step is used for all steps. If\n",
    "            an array, then each element k contains the time  at step k.\n",
    "            Units are seconds.\n",
    "\n",
    "        **Returns**\n",
    "\n",
    "        x : numpy.ndarray\n",
    "           smoothed means\n",
    "\n",
    "        P : numpy.ndarray\n",
    "           smoothed state covariances\n",
    "\n",
    "        K : numpy.ndarray\n",
    "            smoother gain at each step\n",
    "\n",
    "\n",
    "        **Example**\n",
    "\n",
    "        .. code-block:: Python\n",
    "\n",
    "            zs = [t + random.randn()*4 for t in range (40)]\n",
    "\n",
    "            (mu, cov, _, _) = kalman.batch_filter(zs)\n",
    "            (x, P, K) = rts_smoother(mu, cov, fk.F, fk.Q)\n",
    "\n",
    "        \"\"\"\n",
    "        assert len(Xs) == len(Ps)\n",
    "        n, dim_x = Xs.shape\n",
    "\n",
    "        if dt is None:\n",
    "            dt = [self._dt] * n\n",
    "        elif isscalar(dt):\n",
    "            dt = [dt] * n\n",
    "\n",
    "        if Qs is None:\n",
    "            Qs = [self.Q] * n\n",
    "\n",
    "        # smoother gain\n",
    "        Ks = zeros((n,dim_x,dim_x))\n",
    "\n",
    "        num_sigmas = 2*dim_x + 1\n",
    "\n",
    "        xs, ps = Xs.copy(), Ps.copy()\n",
    "        sigmas_f = zeros((num_sigmas, dim_x))\n",
    "\n",
    "\n",
    "        for k in range(n-2,-1,-1):\n",
    "            # create sigma points from state estimate, pass through state func\n",
    "            sigmas = self.points_fn.sigma_points(xs[k], ps[k])\n",
    "            for i in range(num_sigmas):\n",
    "                sigmas_f[i] = self.fx(sigmas[i], dt[k])\n",
    "\n",
    "            # compute backwards prior state and covariance\n",
    "            xb = dot(self.Wm, sigmas_f)\n",
    "            Pb = 0\n",
    "            x = Xs[k]\n",
    "            for i in range(num_sigmas):\n",
    "                y = sigmas_f[i] - x\n",
    "                Pb += self.Wm[i] * outer(y, y)\n",
    "            Pb += Qs[k]\n",
    "\n",
    "            # compute cross variance\n",
    "            Pxb = 0\n",
    "            for i in range(num_sigmas):\n",
    "                z = sigmas[i] - Xs[k]\n",
    "                y = sigmas_f[i] - xb\n",
    "                Pxb += self.Wm[i] * outer(z, y)\n",
    "\n",
    "            # compute gain\n",
    "            K = dot(Pxb, inv(Pb))\n",
    "\n",
    "            # update the smoothed estimates\n",
    "            xs[k] += dot (K, xs[k+1] - xb)\n",
    "            ps[k] += dot3(K, ps[k+1] - Pb, K.T)\n",
    "            Ks[k] = K\n",
    "\n",
    "        return (xs, ps, Ks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "metadata": {
  "name": "",
  "signature": "sha256:d0bfbbe322bb5a6c6b2c484f5f8da49814c5c8d8ec1120813d02a9511ddf94a1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Introduction\n",
      "\n",
      "The Kalman filter belongs to a family of filters called *bayesian filters*. Without going into"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tracking a Dog\n",
      "\n",
      "Let us begin with a simple problem. We have a dog friendly workspace, and so people bring their dogs to work. However, occasionally the dogs wander out of your office and down the halls. We want to be able to track them. So during a hackathon somebody created a little sonar sensor to attach to the dog's collar. It emits a signal, listens for the echo, and based on how quickly an echo comes back we can tell whether the dog is in front of an open doorway or not. It also senses when the dog walks, and reports in which direction the dog has moved. It connects to our network via wifi and sends an update once a second.\n",
      "\n",
      "I want to track my dog Simon, so I attach the device to his collar and then fire up Python, ready to try to write code to track him through the building. At first blush this may appear impossible. If I start listening to the sensor of Simon's collar I might read 'door', 'hall', 'hall', and so on. How can I use that information to determine where Simon is?\n",
      "\n",
      "To keep the problem small, we will assume that there are only 10 positions in a single hallway to consider, which we will number 0 to 9, where 1 is to the right of 0, 2 is to the right of 1, and so on. For reasons that will be clear later, we will also assume that the hallway is circular or rectangular. If you move right from position 9, you will be at position 0.  \n",
      "\n",
      "When I begin listening to the sensor I have no reason to believe that Simon is at any particular position in the hallway. He is equally likely to be in any position. The probability that he is in each position is therefore $1/10$ \n",
      "\n",
      "Let us represent our belief of his position at any time in a numpy array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = array([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's create a map of the hallway in another list. Suppose rehere are first two doors close together, and then another door quite a bit further down the hallway. We will use 1 to denote a door, and 0 to denote a wall:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hallway = array([1, 1, 0, 0, 0, 0, 0, 0, 1, 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So I start listening to Simon's transmissions on the network, and the first data I get from the sesnor is \"door\". From this I conclude that he is in front of a door, but which one? I have no idea. I have no reason to believe is in front of the first, second, or third door. But what I can do is assign a probability to each door. All doors are equally likely, so I assign a probability of 1/3 to each door. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "pos = array([0.333, 0.333, 0., 0., 0., 0., 0., 0., 0.333, 0.])\n",
      "\n",
      "def bar_plot(pos):\n",
      "    ax = plt.figure().gca()\n",
      "    x = np.arange(len(pos))\n",
      "    ax.bar(x, pos)\n",
      "    plt.xticks(x+0.5, x)\n",
      "    plt.show()\n",
      "\n",
      "bar_plot (pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We call this a <i>multimodal</i> distribution because we have multiple beliefs about the position of our dog. Of course we are not saying that we think he is simultaneously in three different locations, merely that so far we have narrowed down our knowledge in his position to these locations. \n",
      "\n",
      "I hand coded the pos array in the code above. How would we implement this in code? Well, hallway represents each door as a 1, and wall as 0, so we will multiply the hallway variable by the percentage, like so;"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = hallway * 0.3\n",
      "print 'pos =', pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Extracting Information from Multiple Sensor Readings\n",
      "Let's put Python aside and think about the problem a bit. Suppose we were to read the following from Simon's sensor:\n",
      "\n",
      "  * door\n",
      "  * move right\n",
      "  * door\n",
      "  \n",
      "\n",
      "Can we deduce where Simon is at the end of that sequence? Of course! Given the hallway's layout there is only one place where you can be in front of a door, move once to the right, and be in front of another door, and that is at the left end. Therefore we can confidently state that Simon is in front of the second doorway. If this is not clear, suppose Simon had started at the second or third door. After moving to the right, his sensor would have returned 'wall'. Therefore the only possibility is that he is now in front of the second door. We denote this in Python with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = array([0,1,0,0,0,0,0,0,0,0])\n",
      "print pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Obviously I carefully constructed the hallway layout and sensor readings to give us an exact answer quickly. Real problems will not be so clear cut. But this should trigger your intuition - the first sensor reading only gave us very low probabilities (0.333) for Simon's location, but after a position update and another sensor reading we knew much more about where he is. You might suspect, correctly, that if you had a very long hallway with a large number of doors that after several sensor readings and positions updates we would either be able to know where Simon was, or have the possibilities narrowed down to a small number of possibilities. For example, suppose we had a long sequence of \"door, right, door, right, wall, right, wall, right, door, right, door, right, wall, right, wall, right, wall, right, wall, right, door\". Simon could only be located where we had a sequence of [1,1,0,0,1,1,0,0,0,0,1] in the hallway. There might be only one match for that, or at most a few. Either way we will be far more certain about his position then when we started.\n",
      "\n",
      "We could work through the code to implement this solution, but instead let us consider a real world complication to the problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Noisy Sensors\n",
      "Unfortunately I have yet to come across a perfect sensor. Perhaps the sensor would not detect a door if Simon sat in front of it while scratching himself, or it might report there is a door if he is facing towards the wall, not down the hallway. So in practice when I get a report 'door' I cannot assign 1/3 as the probability for each door. I have to assign something less than 1/3 to each door, and then assign a small probability to each blank wall position. At this point it doesn't matter exactly what numbers we assign; let us say that the probably of 'door' being correct is 0.6, and the probability of being incorrect is 0.2, which is another way of saying it is about 3 times more likely to be right than wrong. How would we do this?\n",
      "\n",
      "At first this may seem like an insurmountable problem. If the sensor is noisy it casts doubt on every piece of data. How can we conclude anything if we are always unsure?\n",
      "\n",
      "The key, as with the problem above, is probabilities. We are already comfortable with assigning a probabilistic belief about the location of the dog; now we just have to incorporate the additional uncertainty caused by the sensor noise. Say we think there is a 50% chance that our dog is in front of a specific door and we get a reading of 'door'. Well, we think that is only likely to be true 0.6 of the time, so we multiply: $0.5 * 0.6= 0.3$. Likewise, if we think the chances that our dog is in front of a wall is 0.1, and the reading is 'door', we would multiply the probability by the chances of a miss: $0.1 * 0.2 = 0.02$.\n",
      "\n",
      "However, we more or less chose 0.6 and 0.2 at random; if we multiply the pos array by these values the end result will no longer represent a true probability distribution. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def measure (pos, measure, p_hit, p_miss):\n",
      "    q = array(pos, dtype=float)\n",
      "    for i in range(len(hallway)):\n",
      "        if hallway[i] == measure:\n",
      "            q[i] = pos[i] * p_hit\n",
      "        else:\n",
      "            q[i] = pos[i] * p_miss\n",
      "    return q\n",
      "\n",
      "pos = array([0.2]*10)\n",
      "reading = 1 # 1 is 'door'\n",
      "pos = measure (pos, 1, .6, .2)\n",
      "\n",
      "print pos\n",
      "print 'sum =', sum(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that this is not a probability distribution because it does not sum to 1.0. But we can see that the code is doing mostly the right thing - the doors are assigned a number (0.12) that is 3 times higher than the walls (0.04). So we can write a bit of code to normalize the result so that the probabilities correctly sum to 1.0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize (p):\n",
      "    s = sum(p)\n",
      "    for i in range (len(p)):\n",
      "        p[i] = p[i] / s\n",
      "        \n",
      "def sense (pos, measure, p_hit, p_miss):\n",
      "    q = array(pos, dtype=float)\n",
      "    for i in range(len(hallway)):\n",
      "        if hallway[i] == measure:\n",
      "            q[i] = pos[i] * p_hit\n",
      "        else:\n",
      "            q[i] = pos[i] * p_miss\n",
      "    normalize(q)\n",
      "    return q\n",
      "\n",
      "\n",
      "pos = array([0.2]*10)\n",
      "reading = 1 # 1 is 'door'\n",
      "pos = sense (pos, 1, .6, .2)\n",
      "\n",
      "print 'sum =', sum(pos)\n",
      "print 'probability of door =', pos[0]\n",
      "print 'probability of wall =', pos[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Normalization is done by dividing each element by the sum of all elements in the list. If this is not clear you should spend a few minutes proving it to yourself algebraically. We can see from the output that the sum is now 1.0, and that the probability of a door vs wall is still three times larger. The result also fits our intuitiion that the probability of a door must be less than 0.333, and that the probability of a wall must be greater than 0.0. Finally, it should fit our intuition that we have not yet been given any information that would allow us to distinguish between any given door or wall position, so all door positions should have the same value, and the same should be true for wall positions. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Incorporating Movement Data\n",
      "\n",
      "Recall how quickly we were able to find an exact solution to our dog's position when we incorporated a series of measurements and movement updates. However, that occured in a fictional world of perfect sensors. Might we be able to find an exact solution even in the presense of noisy sensors?\n",
      "\n",
      "Unfortunately, the answer is no. Even if the sensor readings perfectly match an extremely complicated hallway map we could not say that we are 100% sure that the dog is in a specific position - there is, after all, the possibility that every sensor reading was wrong! Naturally, in a more typical situation most sensor readings will be correct, and we might be close to 100% sure of our answer, but never 100% sure. This may seem head-spinningly complicated, but lets just go ahead and program the math, which as we have seen is quite simple.\n",
      "\n",
      "First let's deal with the simple case - assume the movement sensor is perfect, and it reports that the dog has moved one space to the right. How would we alter our pos array?\n",
      "\n",
      "I hope after a moment's thought it is clear that we should just shift all the values one space to the right. If we previously thought there was  a 50% chance of simon being at position 3, then after the move to the right we should believe that there is a 50% chance he is at position 4. So let's implement that. Recall that the hallway is circular, so we will use modulo arithmetic to perform the shift correctly"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "def perfect_update(pos, move):\n",
      "    \"\"\" move the position by 'move' spaces, where positive is to the right, and negative\n",
      "    is to the left\n",
      "    \"\"\"\n",
      "    n = len(pos)\n",
      "    result = array(pos, dtype=float)\n",
      "    for i in range(n):\n",
      "        result[i] = pos[(i-move) % n]\n",
      "    return result\n",
      "        \n",
      "pos = array([.4, .1, .2, .3])\n",
      "print 'pos before update =', pos\n",
      "pos = perfect_update(pos, 1)\n",
      "print 'pos after update =', pos\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that we correctly shifted all values one position to the right, wrapping from the end of the array back to the beginning.\n",
      "\n",
      "#### Adding Noise to the Update\n",
      "\n",
      "We want to solve real world problems, and we have already stated that all sensors have noise. Therefore the code above must be wrong. What if the sensor detected our dog moving 1 space, but he actually moved 2 spaces, or 0? Once again this may initially sound like an insummountable problem, but let's just model it in math. Since this is just an example, we will create a pretty simple noise model for the sensor - later in the book we will handle far more sophisticated errors.\n",
      "\n",
      "We will say that when the sensor sends a movement update, it is 80% likely to be right, and it is 10% likely to overshoot one position to the right, and 10% likely to undershoot to the left. That is, if we say the movement was 4 (meaning 4 spaces to the right), the dog is 80% likely to have moved 4 spaces to the right, 10% to have moved 3 spaces, and 10% to have moved 5 spaces.\n",
      "\n",
      "This is slightly harder than the math we have done so far, but it is still tractable. Each result in the array now needs to incorporate probabilities for 3 different situations. For example, consider position 9 for the case where the reported movement is 2. It should be clear that after the move we need to incorporate the probability that was at position 7 (9-2). However, there is a small chance that our dog actually moved from either 1 or 3 spaces away due to the sensor noise, so we also need to use positions 6 and 8. How much? Well, we have the probabilities, so we can just multiply and add. It would be 80% of position 7 plus 10% of position 6 and 10% of position 8! Let's try coding that:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def update (pos, move, p_correct, p_under, p_over):\n",
      "    n = len(pos)\n",
      "    result = array(pos, dtype=float)\n",
      "    for i in range(n):\n",
      "                result[i] =  \\\n",
      "            pos[(i-move) % n]   * p_correct + \\\n",
      "            pos[(i-move-1) % n] * p_over + \\\n",
      "            pos[(i-move+1) % n] * p_under          \n",
      "    return result\n",
      "\n",
      "p = array([0,0,0,1,0,0,0,0])\n",
      "res = update (p, 2, .8, .1, .1)\n",
      "print res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The simple test case that we ran appears to work correctly. We initially believed that the dog was in position 3 with 100% certainty; after the movement update we now give an 80% probability to the dog being in position 5, and a 10% chance to undershooting to position 4, and a 10% chance of overshooting to position 6. Let us look at a case where we have multiple beliefs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = array([0, 0, .4, .6, 0, 0, 0, 0])\n",
      "res = update (p, 2, .8, .1, .1)\n",
      "print res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here the results are more complicated, but you should still be able to work it out in your head. The 0.04 is due to the possibility that the 0.4 belief undershot by 1. The 0.38 is due to the following: the 80% chance that we moved 2 positions $(.4 * .8)$ and the 10% chance that we undershot $(.6*.1)$. Overshooting plays no role here because if we overshot both .4 and .6 would be past this position. **I strongly suggest working some examples until all of this is very clear, as so much of what follows depends on understanding this step.**\n",
      "\n",
      "If you look at the probabilities after performing the update you probably feel dismay. In the example above we started with probabilitys of .4 and .6 in two fields; after performing the update the probabilities are not only lowered, but they are strewn out across the map."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bar_plot (res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is not a coincidence, or the result of a carefully chosen example - it is always true of the update step. This is inevitable; if our sensor is noisy we will lose a bit of information on every update. Suppose we were to perform the update an infinite number of times - what would the result be? If we lose information on every step, we must eventually end up with no information at all, and our probabilities will be equally distributed across the pos array. Let's try this with say 500 iterations.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = [1.0,0,0,0,0,0,0,0,0,0]\n",
      "for i in range (500):\n",
      "    pos = update(pos, 1, .8, .1, .1)\n",
      "print pos\n",
      "bar_plot(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After 500 iterations we have lost all information, even though we were 100% sure that we started in position 1. Feel free to play with the numbers to see the effect of different number of updates. For example, after 100 updates we have a small amount of information left.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = [1.0,0,0,0,0,0,0,0,0,0]\n",
      "for i in range (100):\n",
      "    pos = update(pos, 1, .8, .1, .1)\n",
      "print pos\n",
      "bar_plot(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Integrating Measurements and Movement Updates\n",
      "\n",
      "The problem of loosing information during an update may make it seem as if our system would quickly devolve into no knowledge. However, recall that our process is not an endless series of updates, but of *measure->update->measure->update->measure->update...* The output of the measure step is fed into the update. The update step, with a degraded certainty, is then fed into the measure step. \n",
      "\n",
      "Let's think about this intuitively. After the first measure->update round we have degraded the knowledge we gained by the measurement by a small amount. But now we take another measurement. When we try to incorporate that new measurement into our belief, do we become more certain, less certain, or equally certain. Consider a simple case - you are sitting in your office. A co-worker asks another co-worker where you are, and they report \"in his office\". You keep sitting there while they ask and answer \"has he moved\"? \"No\" \"Where is he\" \"In his office\". Eventually you get up and move, and lets say the person didn't see you move. At that time the questions will go \"Has he moved\" \"no\" (but you have!) \"Where is he\" \"In the kitchen\". Wow! At that moment the statement that you haven't moved conflicts strongly with the next measurement that you are in the kitchen. If we were modelling these with probabilities the probability that you are in your office would lowever, and the probability that you are in the kitchen would go up a little bit. But now imagine the subsequent conversation: \"has he moved\" \"no\" \"where is he\" \"in the kitchen\". Pretty quickly the belief that you are in your office would fade away, and the belief that you are in the kitchen would increase to near certainty. The belief that you are in the office will never go to zero, nor will the belief that you are in the kitchen ever go to 1.0 because of the chances of error, but in practice your co-workers would be correct to be quite confident in their system.\n",
      "\n",
      "That is what intuition tells us. What does the math tell us?\n",
      "\n",
      "Well, we have already programmed the measure step, and we have programmed the update step. All we need to do is feed the result of one into the other, and we will have programmed our dog tracker!!! Let's see how it performs. We will input data as if the dog started at position 0 and moved right at each update. However, as in a real world application, we will start with no knowledge and assign equal probability to all positions. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = array([.1]*10)\n",
      "p = sense (p, 1, .6, .2)\n",
      "print p\n",
      "p = update (p, 1, .8, .1, .1)\n",
      "print p\n",
      "bar_plot(p)\n",
      "\n",
      "          "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So after the first sense we have assigned a high probability to each door position, and a low probability to each wall position. The update step shifted these probabilities to the right, smearing them about a bit. Now lets look at what happens at the next sense."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = sense (p, 1, .6, .2)\n",
      "print p\n",
      "bar_plot(p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice the tall bar at position 1. This corresponds with the (correct) case of starting at position 0, sensing a door, shifting 1 to the right, and sensing another door. No other positions make this set of observations as likely. Now lets add an update and then sense the wall."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = update (p, 1, .8, .1, .1)\n",
      "p = sense (p, 0, .6, .2)\n",
      "bar_plot (p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is exciting! We have a very prominent bar at position 2 with a value of around 35%. It is over twice the value of any other bar in the plot, and is about 4% larger than our last plot, where the tallest bar was around 31%. Let's see one more sense->update cycle."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = update (p, 1, .8, .1, .1)\n",
      "p = sense (p, 0, .6, .2)\n",
      "bar_plot (p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here things have degraded a bit due to the long string of wall positions in the map. We cannot be as sure where we are when there is an undifferentiated line of wall positions, so naturally our probabilities spread out a bit."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The Effect of Bad Sensor Data\n",
      "\n",
      "You may be suspicious of the results above because I always passed correct sensor data into the functions. However, we are claiming that this code implements a *filter* - it should filter out bad sensor measurements. Does it do that?\n",
      "\n",
      "To make this easy to program and visualize I will change the layout of the hallway to mostly alternating doors and hallways:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hallway = [1,0,1,0,0,1,0,1,0,0]\n",
      "pos = array([.1]*10)\n",
      "measurements = [1,0,1,0,0]\n",
      "\n",
      "for m in measurements:\n",
      "    pos = sense (pos, m, .6, .2)\n",
      "    pos = update (pos, 1, .8, .1, .1)\n",
      "bar_plot(pos)\n",
      "print pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point we have correctly identified the likely cases, we either started at position 0 or 5, because we saw the following sequence of doors and walls 1,0,1,0,0. But now lets inject a bad measurement, and see what happens:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = sense (pos, m, .6, .2)\n",
      "pos = update (pos, 1, .8, .1, .1)\n",
      "bar_plot(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That one bad measurment appears to have significantly eroded our knowledge. However, note that our highest probabilities are still at 0 and 5, which is correct. Now let's continue with a series of correct measurements"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "measurements = [0,1,0,1,0,0]\n",
      "\n",
      "for m in measurements:\n",
      "    pos = sense (pos, m, .6, .2)\n",
      "    pos = update (pos, 1, .8, .1, .1)\n",
      "bar_plot(pos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see we quickly filtered out the bad sensor reading and converged on the most likely positions for our dog."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Generalizing to Multiple Dimensions\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Summary\n",
      "\n",
      "The code is very small, but the result is huge! We will go into the math more later, but we have implemented a form of a Bayesian filter. It is commonly called a Histogram filter. The Kalman filter is also a Bayesian filter, and uses this same logic to produce it's results. The math is a bit more complicated, but not by much. For now, we will just explain that Bayesian statistics compute the liklihood of the present based on the past. If we know there are two doors in a row, and the sensor reported two doors in a row, it is likely that we are positioned near those doors. Bayesian statistics just formalizes that example, and Bayesian filters formalize filtering data based on that math by implementing the sense->update->sense->update process. \n",
      "\n",
      "We have learned how to start with no information and derive information from noisy sensors. Even though our sensors are very noisey (most sensors are more then 80% accurate, for example) we quickly converge on the most likely position for our dog. We have learned how the update step always degrades our knowledge, but the addition of another measurement, even when it might have noise in it, improves our knowlege, allowing us to converge on the most likely result.\n",
      "\n",
      "If you followed the math carefully you will realize that all of this math is exact. The bar charts that we are displaying are not an *estimate* or *guess* - they are mathematically exact results that exactly represent our knowledge. The knowledge is probabilistic, to be sure, but it is exact, and correct.\n",
      "\n",
      "However, we are a long way from tracking an airplane or a car. This code only handles the 1 dimensional case, whereas cars and planes operate in 2 or 3 dimensions. Also, our position vector is *multimodal*. It expresses multiple beliefs at once. Imagine if your GPS told you \"it's 20% likely that you are here, but 10% likely that you are on this other road, and 5% likely that you are at one of 14 other locations. That would not be very useful information. Also, the data is discrete. We split an area into 10 (or whatever) different locations, whereas in most real world applications we want to work with continuous data. We want to be able to represent moving 1 km, 1 meter, 1 mm, or any arbitrary amount, such as 2.347 cm. \n",
      "\n",
      "Finally, the bar charts may strike you as being a bit less certain than we would want. A 25% certaintly may not give you a lot of confidence in the anwser. Of course, what is important here is the ratio of this probability to the other probabilities in your vector. If the next largest bar is 23% then we are not very knowledgable about our position, whereas if the next largest is 3% we are in fact quite certain. But this is not clear or intuitive. However, there is an extremely important insight that Kalman filters implement that will signficantly improve our accuracy from the same data.\n",
      "\n",
      "Do not be mislead by the simplicity of the example I chose. This is a robust and complete implementation of a histogram filter, and you may use the code in complicated, real world solutions. If you need a multimodal, discrete filter, this filter works.\n",
      "\n",
      "**If you can understand this chapter you will be able to understand and implement Kalman filters** I cannot stress this enough. If anything is murky, go back and reread this chapter and play with the code. the rest of this book will build on the algorithms that we use here. If you don't intuitively understand why this histogram filter works, and can at least work through the math, you will have little success with the rest of the material. However, if you grasp the fundamental insight - multiplying probabilities when we measure, and shifting probabilities when we update leads to a converging solution - then you understand everything important you need to grasp the Kalman filter. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#format the book\n",
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "**Author notes:**\n",
      "    Do I want to go to the multidimensional case? At least describe it, but why not implement it as well"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}